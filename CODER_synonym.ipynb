{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CODER_synonym","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNyzKMaeWHaRhu+oRUVMk+Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"szrODUb01_oh"},"outputs":[],"source":["from gensim import models\n","import os\n","import sys\n","import glob\n","sys.path.append(\"../../\")\n","from load_umls import UMLS\n","import torch\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","# from data_util import load\n","import tqdm\n","import pickle\n","\n","batch_size = 128\n","device = \"cuda:7\""]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from nltk.corpus import stopwords"],"metadata":{"id":"laDsMz2U2HUt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_bert_embed(phrase_list, m, tok, normalize=True, summary_method=\"CLS\", tqdm_bar=False):\n","    input_ids = []\n","    for phrase in phrase_list:\n","        input_ids.append(tok.encode_plus(\n","            phrase, max_length=32, add_special_tokens=True,\n","            truncation=True, pad_to_max_length=True)['input_ids'])\n","    m.eval()\n","\n","    count = len(input_ids)\n","    now_count = 0\n","    with torch.no_grad():\n","        if tqdm_bar:\n","            pbar = tqdm.tqdm(total=count)\n","        while now_count < count:\n","            input_gpu_0 = torch.LongTensor(input_ids[now_count:min(\n","                now_count + batch_size, count)]).to(device)\n","            if summary_method == \"CLS\":\n","                embed = m(input_gpu_0)[1]\n","            if summary_method == \"MEAN\":\n","                embed = torch.mean(m(input_gpu_0)[0], dim=1)\n","            if normalize:\n","                embed_norm = torch.norm(\n","                    embed, p=2, dim=1, keepdim=True).clamp(min=1e-12)\n","                embed = embed / embed_norm\n","            if now_count == 0:\n","                output = embed\n","            else:\n","                output = torch.cat((output, embed), dim=0)\n","            if tqdm_bar:\n","                pbar.update(min(now_count + batch_size, count) - now_count)\n","            now_count = min(now_count + batch_size, count)\n","        if tqdm_bar:\n","            pbar.close()\n","    return output"],"metadata":{"id":"WSkexCoy2LEg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_checkpoint = '/export/home/cse200093/coder_all'\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","model = AutoModel.from_pretrained(model_checkpoint).to(device)"],"metadata":{"id":"GMfdM-L02NjV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load and save umls (execute only once)"],"metadata":{"id":"NWquNTi12T1S"}},{"cell_type":"code","source":["# load french umls\n","umls = UMLS(\"/export/home/cse200093/deep_mlg_normalization/resources/umls/2021AB\", source_range=['BI','CHV','CSP','CST','CVX','DRUGBANK','HPO','ICD10','ICD10CM','ICPC2P','ICPCFRE',\n","                                                                               'LNC','LNC-FR-FR','MDR','MDRFRE','MEDCIN','MMX','MSH','MSHFRE','MTHICD9','MTHMSTFRE',\n","                                                                               'NCBI','NCI','NCI_CDISC','NCI_CTRP','NDDF','OMIM','PDQ','RCD','RXNORM','SNMI','SNOMEDCT_US',\n","                                                                               'SRC','WHO','WHOFRE'], lang_range=['FRE'])"],"metadata":{"id":"ard1AZ4A2Rqh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["umls_label = []\n","umls_label_set = set()\n","umls_des = []\n","\n","for cui in tqdm.tqdm(umls.cui2str):\n","    if not cui in umls_label_set:\n","        tmp_str = list(umls.cui2str[cui])\n","        umls_label.extend([cui] * len(tmp_str))\n","        umls_des.extend(tmp_str)\n","        umls_label_set.update([cui])\n","print(len(umls_des))"],"metadata":{"id":"sTm0fEzE2XSi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["umls_embedding = get_bert_embed(umls_des, model, tokenizer, tqdm_bar=True)"],"metadata":{"id":"w5VQQPQP2YyH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save umls_embedding\n","torch.save(umls_embedding, 'umls_embedding_fr_coder_all.pt')\n","# save umls_label and des\n","open_file = open('umls_des_fr_coder_all.pkl', \"wb\")\n","pickle.dump(umls_des, open_file)\n","open_file.close()\n","\n","open_file = open('umls_label_fr_coder_all.pkl', \"wb\")\n","pickle.dump(umls_label, open_file)\n","open_file.close()"],"metadata":{"id":"PbYqyntU2rH2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Find synonym\n","Use CODER_all to find top 10 synonyms of all queries from umls_des"],"metadata":{"id":"Fqa7f9Cl2fm2"}},{"cell_type":"code","source":["# load queries for 4 types\n","f = open(\"./resources/query_4types.txt\", \"r\")\n","lines = f.readlines()\n","dic_type_query = {}\n","for line in lines:\n","    line = line.rstrip('\\n')\n","    type_name = line.split(':')[0]\n","    query = line.split(':')[1].split(';')\n","    dic_type_query[type_name] = query\n","dic_type_query"],"metadata":{"id":"lfjEPp8X2f48"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load queries in phenotype_to_extract_large\n","f = open(\"./resources/phenotype_to_extract_large.txt\", \"r\")\n","lines = f.readlines()\n","dic_type_query = {}\n","for line in lines:\n","    line = line.rstrip('\\n')\n","    type_name = line.split(':')[0]\n","    query = line.split(':')[1].split(';')\n","    dic_type_query[type_name] = query\n","dic_type_query"],"metadata":{"id":"mp64c2gC2hy4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# step 1: find out all terms with the same cui as query\n","stop_words = list(set(stopwords.words('french')))\n","stop_words.append('sai')\n","\n","dic_query_same_cui = {}\n","for type_name in dic_type_query:\n","    queries = dic_type_query[type_name]\n","    for query in queries:\n","        try:\n","            cui = umls_label[umls_des.index(query.lower().replace('-',' '))]\n","            terms_same_cui = dic_cui_term[cui]\n","            dic_query_same_cui[query] = list(set([x+' ' for x in terms_same_cui if x not in stop_words]))\n","        except:\n","            dic_query_same_cui[query] = []\n","            \n","dic_query_same_cui"],"metadata":{"id":"p1NPbhni2jAZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["queries = [y for x in list(dic_type_query.values()) for y in x]\n","queries_embedding = get_bert_embed(queries, model, tokenizer)"],"metadata":{"id":"RPBZEMfS2lCd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# limit\n","limit = 0.8\n","candidate_terms = {}\n","x_size = queries_embedding.size(0)\n","sim = torch.matmul(queries_embedding, umls_embedding.t())\n","\n","idx_query = torch.where(sim>limit)[0]\n","idx_cand = torch.where(sim>limit)[1]\n","\n","for val in range(len(queries)):\n","    idx = torch.where(idx_query==val)[0]\n","    idx_query_selected = [idx_cand[x] for x in idx]\n","    # terms_selected = [' '+umls_des[x]+' ' for x in idx_query_selected if umls_des[x] not in stop_words]\n","    terms_selected = list(set([umls_des[x].lower() for x in idx_query_selected if umls_des[x] not in stop_words]))\n","    candidate_terms[queries[val]] = [x+' ' for x in terms_selected]\n","\n","candidate_terms"],"metadata":{"id":"6vBRqZD92mGX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for type_name in dic_type_query:\n","    new_val = []\n","    for word in dic_type_query[type_name]:\n","        new_val.append(list(set([word.replace('-',' ').lower()+' ']+candidate_terms[word]+dic_query_same_cui[word])))\n","        # new_val.append([word]+candidate_terms[i])\n","    dic_type_query[type_name] = new_val\n","dic_type_query"],"metadata":{"id":"2g_IUsSa2ney"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save dic_type_query\n","open_file = open(f'dic_type_query_synonym_limit{limit}_same_cui.pkl', \"wb\")\n","pickle.dump(dic_type_query, open_file)\n","open_file.close()"],"metadata":{"id":"k3pA2zVM2o1q"},"execution_count":null,"outputs":[]}]}